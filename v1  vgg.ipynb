{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0df98a7-8be5-412c-9310-988e332dfd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-24 09:56:03.550795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "34193b10-3e4a-4f68-8826-542ed100d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 128\n",
    "IMAGE_SIZE = [size, size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e61dfe90-09f5-4bc7-8979-f902aae3fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=\"/home/nayan/Documents/Thesis/dataset/new clean/train\"\n",
    "test_path= \"/home/nayan/Documents/Thesis/dataset/new clean/test\"\n",
    "val_path=  \"/home/nayan/Documents/Thesis/dataset/new clean/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce29a3e4-72d0-4923-9ac3-88f95861dedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nayan/Documents/Thesis/dataset/new clean/train/Brown_Spot\n",
      "/home/nayan/Documents/Thesis/dataset/new clean/train/Hispa\n",
      "/home/nayan/Documents/Thesis/dataset/new clean/train/Leaf_Blast\n"
     ]
    }
   ],
   "source": [
    "x_train=[]\n",
    "\n",
    "for folder in os.listdir(train_path):\n",
    "    sub_path=train_path+\"/\"+folder\n",
    "    print(sub_path)\n",
    "    for img in os.listdir(sub_path):\n",
    "        image_path=sub_path+\"/\"+img\n",
    "        img_arr=cv2.imread(image_path)\n",
    "        img_arr=cv2.resize(img_arr,(size,size))\n",
    "        x_train.append(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "65f741be-f575-461a-a75e-a232b387d6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nayan/Documents/Thesis/dataset/new clean/test/Brown_Spot\n",
      "/home/nayan/Documents/Thesis/dataset/new clean/test/Hispa\n",
      "/home/nayan/Documents/Thesis/dataset/new clean/test/Leaf_Blast\n"
     ]
    }
   ],
   "source": [
    "x_test=[]\n",
    "\n",
    "for folder in os.listdir(test_path):\n",
    "    sub_path=test_path+\"/\"+folder\n",
    "    print(sub_path)\n",
    "    for img in os.listdir(sub_path):\n",
    "        image_path=sub_path+\"/\"+img\n",
    "        img_arr=cv2.imread(image_path)\n",
    "        img_arr=cv2.resize(img_arr,(size,size))\n",
    "        x_test.append(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73824b1c-16ec-4247-aac3-051f966ce993",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val=[]\n",
    "\n",
    "for folder in os.listdir(val_path):\n",
    "    sub_path=val_path+\"/\"+folder\n",
    "    for img in os.listdir(sub_path):\n",
    "        image_path=sub_path+\"/\"+img\n",
    "        img_arr=cv2.imread(image_path)\n",
    "        img_arr=cv2.resize(img_arr,(size,size))\n",
    "        x_val.append(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "410e17c9-ce12-4503-8c3d-7a114ea5d9d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x=np.array(x_train)\n",
    "test_x=np.array(x_test)\n",
    "val_x=np.array(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a3eff9f3-64ed-47aa-913c-94de4856cea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((441, 128, 128, 3), (76, 128, 128, 3), (76, 128, 128, 3))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,test_x.shape,val_x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5c29ed36-bc14-4885-bef1-f42b317385fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train_x/255.0\n",
    "test_x=test_x/255.0\n",
    "val_x=val_x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "09cd1223-a8ea-4dfb-8872-70731a2b7761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be2fad7c-b265-4cdc-abc6-7ab7ca77b6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 441 images belonging to 3 classes.\n",
      "Found 76 images belonging to 3 classes.\n",
      "Found 76 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "#                                    shear_range = 0.2,\n",
    "#                                    zoom_range = 0.2,\n",
    "#                                    horizontal_flip = True)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size = (size, size),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'sparse')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_path,\n",
    "                                            target_size = (size, size),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'sparse')\n",
    "\n",
    "val_set = val_datagen.flow_from_directory(val_path,\n",
    "                                            target_size = (size, size),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "36b6feb9-ddd5-4f25-83fd-510411c6c2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Brown_Spot': 0, 'Hispa': 1, 'Leaf_Blast': 2}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49cd7a51-3f9c-4ce9-9a17-f78f3cadd5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((441,), (76,), (76,))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y=training_set.classes\n",
    "test_y=test_set.classes\n",
    "val_y=val_set.classes\n",
    "train_y.shape,test_y.shape,val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef7c609e-82c7-4a5d-a218-29fbf791fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preprocessing layer to the front of VGG\n",
    "vgg = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "794f707b-8462-4730-8489-831b9fac3702",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb416686-0f86-486c-9013-b97c2379c655",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(vgg.output)\n",
    "\n",
    "prediction = Dense(3, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ba74f22e-723b-4162-9d23-bd4549a69f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 24579     \n",
      "=================================================================\n",
      "Total params: 20,048,963\n",
      "Trainable params: 24,579\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create a model object\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "\n",
    "# view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "657a9aea-f7aa-4ea1-bcae-9ebcf4854dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  optimizer=\"adam\",\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9d128cdd-7342-46eb-b62f-ba0bfdacbb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 4s 309ms/step - loss: 0.1413 - accuracy: 0.9773 - val_loss: 0.5487 - val_accuracy: 0.8421\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 5s 328ms/step - loss: 0.1442 - accuracy: 0.9796 - val_loss: 0.5679 - val_accuracy: 0.8289\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 4s 317ms/step - loss: 0.1377 - accuracy: 0.9841 - val_loss: 0.6227 - val_accuracy: 0.8026\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 4s 323ms/step - loss: 0.1362 - accuracy: 0.9773 - val_loss: 0.6132 - val_accuracy: 0.8158\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 5s 328ms/step - loss: 0.1243 - accuracy: 0.9819 - val_loss: 0.5616 - val_accuracy: 0.8553\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 4s 325ms/step - loss: 0.1165 - accuracy: 0.9819 - val_loss: 0.5663 - val_accuracy: 0.8553\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 4s 325ms/step - loss: 0.1135 - accuracy: 0.9819 - val_loss: 0.5061 - val_accuracy: 0.8684\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 4s 323ms/step - loss: 0.1104 - accuracy: 0.9819 - val_loss: 0.5475 - val_accuracy: 0.8553\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 4s 322ms/step - loss: 0.1042 - accuracy: 0.9819 - val_loss: 0.6115 - val_accuracy: 0.8289\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 5s 326ms/step - loss: 0.1023 - accuracy: 0.9841 - val_loss: 0.5763 - val_accuracy: 0.8553\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.1033 - accuracy: 0.9841 - val_loss: 0.5925 - val_accuracy: 0.8289\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0985 - accuracy: 0.9864 - val_loss: 0.6119 - val_accuracy: 0.8421\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 5s 337ms/step - loss: 0.0911 - accuracy: 0.9864 - val_loss: 0.5428 - val_accuracy: 0.8553\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 5s 338ms/step - loss: 0.0914 - accuracy: 0.9841 - val_loss: 0.5262 - val_accuracy: 0.8553\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 5s 342ms/step - loss: 0.0871 - accuracy: 0.9841 - val_loss: 0.6000 - val_accuracy: 0.8421\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 5s 346ms/step - loss: 0.0848 - accuracy: 0.9841 - val_loss: 0.5635 - val_accuracy: 0.8421\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 5s 343ms/step - loss: 0.0840 - accuracy: 0.9864 - val_loss: 0.6199 - val_accuracy: 0.8158\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 5s 365ms/step - loss: 0.0809 - accuracy: 0.9864 - val_loss: 0.5295 - val_accuracy: 0.8553\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 5s 362ms/step - loss: 0.0776 - accuracy: 0.9887 - val_loss: 0.4716 - val_accuracy: 0.8684\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 5s 368ms/step - loss: 0.0787 - accuracy: 0.9909 - val_loss: 0.5271 - val_accuracy: 0.8553\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 5s 363ms/step - loss: 0.0754 - accuracy: 0.9932 - val_loss: 0.5673 - val_accuracy: 0.8421\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 5s 356ms/step - loss: 0.0689 - accuracy: 0.9909 - val_loss: 0.5777 - val_accuracy: 0.8421\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 5s 350ms/step - loss: 0.0687 - accuracy: 0.9887 - val_loss: 0.5037 - val_accuracy: 0.8553\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 5s 350ms/step - loss: 0.0659 - accuracy: 0.9887 - val_loss: 0.5549 - val_accuracy: 0.8421\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 5s 338ms/step - loss: 0.0645 - accuracy: 0.9909 - val_loss: 0.5052 - val_accuracy: 0.8553\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 5s 351ms/step - loss: 0.0696 - accuracy: 0.9887 - val_loss: 0.4903 - val_accuracy: 0.8553\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 5s 350ms/step - loss: 0.0631 - accuracy: 0.9932 - val_loss: 0.5583 - val_accuracy: 0.8553\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 5s 350ms/step - loss: 0.0629 - accuracy: 0.9955 - val_loss: 0.5785 - val_accuracy: 0.8289\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 5s 365ms/step - loss: 0.0594 - accuracy: 0.9932 - val_loss: 0.5976 - val_accuracy: 0.8553\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 5s 370ms/step - loss: 0.0604 - accuracy: 0.9955 - val_loss: 0.5046 - val_accuracy: 0.8553\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history = model.fit(\n",
    "  train_x,\n",
    "  train_y,\n",
    "  validation_data=(val_x,val_y),\n",
    "  epochs=30,  \n",
    "  batch_size=32,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e22bab-dd8e-4a22-b1aa-6e6c9ac2e49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538832c-06f6-4794-970a-a9d4eeeb39d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
